数据边界，是目前接手的系统，很大的一个问题，数据和业务耦合性太强，需要有方案能尽可能的分离它们。


数据边界的宗旨是隔离外部原始数据和内部业务数据，在数据结构的维度实现边界和职责划分，以此来缓冲外部污染数据对内部业务逻辑的冲击力。

我们应该有这样的认识：外部原始数据永远是不可靠的。对于内层业务逻辑来说，外部数据来源有很多种，网络，文件，数据库等等，这些数据来源都是不可靠的，网络不稳定，服务器故障，磁盘文件被误写都是不可避免的。如果任由这部分污染数据直接传递到业务层逻辑，业务层逻辑在没有足够防御的情况下就会运转失常甚至于崩溃。退一步讲，即使业务层逻辑做了足够的防御，可以抑制污染数据的破坏力，从职责划分上讲已经出现了问题: 业务逻辑承担了它不应该承担的数据防御职责。

另一个设计上的缺陷是：业务逻辑直接套用了外部原始数据的数据载体，这样导致业务层数据处理逻辑和外部原始数据的格式等信息发生了强耦合，在数据表示层两者没有得到区分，这其实是一个在数据结构上职责没有划分的问题。

上述设计缺陷的解决方案最终形成了数据边界。解决方案有这么几个要点:

    数据校验的职责从业务逻辑中剥离，形成单独的职能模块；

    外部原始数据的数据载体要和业务逻辑的数据载体做到完全隔离；

    所有的外部数据入口要得到有效的控制
    
   ![数据边界](https://github.com/Gamehu/files/blob/master/640.jpg)
 
    只有控制了所有外部数据入口，才能对所有外部数据做校验，而数据载体隔离需要的数据转换也需要依托对所有外部数据入口的控制，数据校验可以作为数据转换的前置步骤。数据边界的示意图如下:

每一个外部数据入口都有一道关卡: Data Mapper, 这就是上面第一点提到的独立职能模块，Data Mapper扮演外部数据运输到内部的关卡，Data Mapper承载了两个职责: 数据校验和数据转换（因为这两个职责本身是前后关联的，没有必要再次进行模块级的拆分）

1.数据校验: 按照业务特性或者规范约定，对外部原始数据进行一次全面排查:如果数据在整体上已经被污染，那么该数据会被彻底放弃，但会被转换为空数据或者约定好的无效数据（比如Java中的null）传递给业务层（数据到达本身也是一个信息，需要业务层知晓。

比如加载数据会显示加载中界面，即使返回了污染数据，也是需要停止显示加载中界面而显示空页面或者错误页面的，如果直接忽略此次数据的到达，那么就会一直显示加载中）如果数据只是部分污染，那么会尝试剔除被污染的部分，以实现力所能及的信息传递。总结来说，数据校验将数据洗白，保证数据的安全性，至于数据的功能性则由数据转换来保证。

2.数据转换: 相对数据校验要复杂一些，需要根据外部原始数据组装出可用的业务层数据，除了单纯的数据结构调整外，还有可能会有数据裁剪，数据拼接等复合操作。数据转换还有一个作用是保持整体业务数据的规范性，比如对于车辆价格这类数据，在业务层面会对有一个精度方面的规范约束（最多两位小数）, 如果得到的数据没有遵循这个规范，我们称其为违规数据，违规数据和污染数据是有区别的，前者可以在数据转换中得到矫正，从而保证了传递给业务层的数据的规范性。

如上图中Data Mapper示意图所示: 通过数据校验和数据转换的协力，各种各样正常的，残缺的，污染的，违规的外部原始数据最终被转化为安全的，规范的，可用的业务层数据。数据边界犹如一个数据沙盒，在业务层来看，它感知到的是一个绝对可靠的业务数据环境。

数据边界的思想内核其实是分层化，职责下放到不同的层，每一层向上一层提供特定的服务，上一层不必关心下面的细节，每一层功能和职责专一化。
